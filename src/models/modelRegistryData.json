{
  "parakeetModels": {
    "parakeet-tdt-0.6b-v3": {
      "name": "Parakeet TDT 0.6B",
      "description": "Fast multilingual ASR with auto language detection (25 languages)",
      "size": "680MB",
      "sizeMb": 680,
      "language": "multilingual",
      "supportedLanguages": [
        "bg",
        "hr",
        "cs",
        "da",
        "nl",
        "en",
        "et",
        "fi",
        "fr",
        "de",
        "el",
        "hu",
        "it",
        "lv",
        "lt",
        "mt",
        "pl",
        "pt",
        "ro",
        "sk",
        "sl",
        "es",
        "sv",
        "ru",
        "uk"
      ],
      "recommended": true,
      "downloadUrl": "https://github.com/k2-fsa/sherpa-onnx/releases/download/asr-models/sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8.tar.bz2",
      "extractDir": "sherpa-onnx-nemo-parakeet-tdt-0.6b-v3-int8"
    }
  },
  "whisperModels": {
    "tiny": {
      "name": "Tiny",
      "description": "Fastest, lower quality",
      "size": "75MB",
      "sizeMb": 75,
      "fileName": "ggml-tiny.bin",
      "downloadUrl": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin"
    },
    "base": {
      "name": "Base",
      "description": "Good balance",
      "size": "142MB",
      "sizeMb": 142,
      "fileName": "ggml-base.bin",
      "downloadUrl": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin",
      "recommended": true
    },
    "small": {
      "name": "Small",
      "description": "Better quality, slower",
      "size": "466MB",
      "sizeMb": 466,
      "fileName": "ggml-small.bin",
      "downloadUrl": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin"
    },
    "medium": {
      "name": "Medium",
      "description": "High quality",
      "size": "1.5GB",
      "sizeMb": 1500,
      "fileName": "ggml-medium.bin",
      "downloadUrl": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin"
    },
    "large": {
      "name": "Large",
      "description": "Best quality, slowest",
      "size": "3GB",
      "sizeMb": 3000,
      "fileName": "ggml-large-v3.bin",
      "downloadUrl": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large-v3.bin"
    },
    "turbo": {
      "name": "Turbo",
      "description": "Fast with good quality",
      "size": "1.6GB",
      "sizeMb": 1600,
      "fileName": "ggml-large-v3-turbo.bin",
      "downloadUrl": "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large-v3-turbo.bin"
    }
  },
  "transcriptionProviders": [
    {
      "id": "openai",
      "name": "OpenAI",
      "baseUrl": "https://api.openai.com/v1",
      "models": [
        {
          "id": "gpt-4o-mini-transcribe",
          "name": "GPT-4o Mini Transcribe",
          "description": "Fast and accurate transcription"
        },
        {
          "id": "gpt-4o-transcribe",
          "name": "GPT-4o Transcribe",
          "description": "Most accurate transcription"
        },
        {
          "id": "whisper-1",
          "name": "Whisper",
          "params": "1.5B",
          "description": "Original Whisper model"
        }
      ]
    },
    {
      "id": "groq",
      "name": "Groq",
      "baseUrl": "https://api.groq.com/openai/v1",
      "models": [
        {
          "id": "whisper-large-v3-turbo",
          "name": "Whisper Large v3 Turbo",
          "params": "809M",
          "description": "216x real-time, good balance of speed and quality"
        },
        {
          "id": "whisper-large-v3",
          "name": "Whisper Large v3",
          "params": "1.55B",
          "description": "299x real-time, highest accuracy, multilingual"
        }
      ]
    },
    {
      "id": "mistral",
      "name": "Mistral",
      "baseUrl": "https://api.mistral.ai/v1",
      "models": [
        {
          "id": "voxtral-mini-latest",
          "name": "Voxtral Mini",
          "params": "3B",
          "description": "Fast multilingual transcription, 13 languages"
        }
      ]
    },
    {
      "id": "qwen",
      "name": "Qwen",
      "baseUrl": "https://dashscope-intl.aliyuncs.com/compatible-mode/v1",
      "models": [
        {
          "id": "qwen3-asr-flash",
          "name": "Qwen3 ASR Flash",
          "description": "Fast multilingual ASR, excellent for CJK languages"
        }
      ]
    },
    {
      "id": "openrouter",
      "name": "OpenRouter",
      "baseUrl": "https://openrouter.ai/api/v1",
      "models": []
    }
  ],
  "cloudProviders": [
    {
      "id": "openai",
      "name": "OpenAI",
      "models": [
        {
          "id": "gpt-5.2",
          "name": "GPT-5.2",
          "description": "Latest flagship reasoning model"
        },
        {
          "id": "gpt-5.2-pro",
          "name": "GPT-5.2 Pro",
          "description": "Harder thinking, best answers"
        },
        {
          "id": "gpt-5-mini",
          "name": "GPT-5 Mini",
          "description": "Fast and cost-efficient"
        },
        {
          "id": "gpt-5-nano",
          "name": "GPT-5 Nano",
          "description": "Ultra-fast, lowest latency"
        },
        {
          "id": "gpt-4.1",
          "name": "GPT-4.1",
          "description": "Strong baseline, 1M context"
        },
        {
          "id": "gpt-4.1-mini",
          "name": "GPT-4.1 Mini",
          "description": "Smaller GPT-4.1 model"
        },
        {
          "id": "gpt-4.1-nano",
          "name": "GPT-4.1 Nano",
          "description": "Lowest latency GPT-4.1"
        }
      ]
    },
    {
      "id": "anthropic",
      "name": "Anthropic",
      "models": [
        {
          "id": "claude-opus-4-6",
          "name": "Claude Opus 4.6",
          "description": "Most intelligent, coding and agents"
        },
        {
          "id": "claude-sonnet-4-5",
          "name": "Claude Sonnet 4.5",
          "description": "Best speed-intelligence balance"
        },
        {
          "id": "claude-haiku-4-5",
          "name": "Claude Haiku 4.5",
          "description": "Fastest, near-frontier intelligence"
        }
      ]
    },
    {
      "id": "gemini",
      "name": "Google Gemini",
      "models": [
        {
          "id": "gemini-3-pro-preview",
          "name": "Gemini 3 Pro",
          "description": "Next-gen flagship for complex reasoning"
        },
        {
          "id": "gemini-3-flash-preview",
          "name": "Gemini 3 Flash",
          "description": "Ultra-fast next-gen model"
        },
        {
          "id": "gemini-2.5-pro",
          "name": "Gemini 2.5 Pro",
          "description": "Stable flagship with deep thinking"
        },
        {
          "id": "gemini-2.5-flash",
          "name": "Gemini 2.5 Flash",
          "description": "Stable fast model, 1M context"
        },
        {
          "id": "gemini-2.5-flash-lite",
          "name": "Gemini 2.5 Flash Lite",
          "params": "0.8B",
          "description": "Lowest latency and cost"
        }
      ]
    },
    {
      "id": "groq",
      "name": "Groq",
      "models": [
        {
          "id": "meta-llama/llama-4-maverick-17b-128e-instruct",
          "name": "LLaMA 4 Maverick",
          "params": "400B MoE",
          "description": "Latest Meta model, 17B active, 128 experts"
        },
        {
          "id": "meta-llama/llama-4-scout-17b-16e-instruct",
          "name": "LLaMA 4 Scout",
          "params": "109B MoE",
          "description": "Latest Meta model, 17B active, 16 experts"
        },
        {
          "id": "qwen/qwen3-32b",
          "name": "Qwen3 32B",
          "params": "32B",
          "description": "Powerful reasoning, 131K context",
          "disableThinking": true
        },
        {
          "id": "openai/gpt-oss-120b",
          "name": "GPT-OSS 120B",
          "params": "117B MoE",
          "description": "OpenAI open-source flagship, 5.1B active"
        },
        {
          "id": "openai/gpt-oss-20b",
          "name": "GPT-OSS 20B",
          "params": "21B MoE",
          "description": "Fast open-source model, 3.6B active"
        },
        {
          "id": "llama-3.3-70b-versatile",
          "name": "LLaMA 3.3 70B",
          "params": "70B",
          "description": "Meta's versatile model, 280 T/sec"
        },
        {
          "id": "llama-3.1-8b-instant",
          "name": "LLaMA 3.1 8B",
          "params": "8B",
          "description": "Ultra-fast 560 T/sec, 131K context"
        }
      ]
    },
    {
      "id": "qwen",
      "name": "Qwen",
      "models": [
        {
          "id": "qwen3-235b-a22b",
          "name": "Qwen3 235B",
          "params": "235B MoE",
          "description": "Flagship MoE, 22B active parameters"
        },
        {
          "id": "qwen3-32b",
          "name": "Qwen3 32B",
          "params": "32B",
          "description": "Dense model with strong reasoning"
        }
      ]
    },
    {
      "id": "openrouter",
      "name": "OpenRouter",
      "models": []
    }
  ],
  "localProviders": [
    {
      "id": "qwen",
      "name": "Qwen",
      "baseUrl": "https://huggingface.co",
      "promptTemplate": "<|im_start|>system\n{system}<|im_end|>\n<|im_start|>user\n{user}<|im_end|>\n<|im_start|>assistant\n",
      "models": [
        {
          "id": "qwen3-8b-q4_k_m",
          "name": "Qwen3 8B",
          "size": "5.0GB",
          "sizeBytes": 5402263552,
          "description": "Latest Qwen3 with thinking mode support",
          "fileName": "Qwen3-8B-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 131072,
          "hfRepo": "Qwen/Qwen3-8B-GGUF",
          "recommended": true
        },
        {
          "id": "qwen3-8b-q5_k_m",
          "name": "Qwen3 8B (Q5)",
          "size": "5.9GB",
          "sizeBytes": 6281625600,
          "description": "Higher quality Qwen3 with thinking mode",
          "fileName": "Qwen3-8B-Q5_K_M.gguf",
          "quantization": "q5_k_m",
          "contextLength": 131072,
          "hfRepo": "Qwen/Qwen3-8B-GGUF"
        },
        {
          "id": "qwen3-4b-q4_k_m",
          "name": "Qwen3 4B",
          "size": "2.5GB",
          "sizeBytes": 2684354560,
          "description": "Compact Qwen3 with reasoning capabilities",
          "fileName": "Qwen3-4B-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 131072,
          "hfRepo": "Qwen/Qwen3-4B-GGUF"
        },
        {
          "id": "qwen3-1.7b-q8_0",
          "name": "Qwen3 1.7B",
          "size": "1.8GB",
          "sizeBytes": 1965555712,
          "description": "Small but capable Qwen3 model",
          "fileName": "Qwen3-1.7B-Q8_0.gguf",
          "quantization": "q8_0",
          "contextLength": 131072,
          "hfRepo": "Qwen/Qwen3-1.7B-GGUF"
        },
        {
          "id": "qwen3-0.6b-q8_0",
          "name": "Qwen3 0.6B",
          "size": "0.6GB",
          "sizeBytes": 686817280,
          "description": "Tiny Qwen3 for edge devices",
          "fileName": "Qwen3-0.6B-Q8_0.gguf",
          "quantization": "q8_0",
          "contextLength": 131072,
          "hfRepo": "Qwen/Qwen3-0.6B-GGUF"
        },
        {
          "id": "qwen3-32b-q4_k_m",
          "name": "Qwen3 32B",
          "size": "19.8GB",
          "sizeBytes": 21260251955,
          "description": "Most powerful local Qwen3 with deep reasoning",
          "fileName": "Qwen3-32B-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 131072,
          "hfRepo": "Qwen/Qwen3-32B-GGUF"
        },
        {
          "id": "qwen2.5-0.5b-instruct-q5_k_m",
          "name": "Qwen2.5 0.5B",
          "size": "0.5GB",
          "sizeBytes": 548405248,
          "description": "Smallest model, fast but limited capabilities",
          "fileName": "qwen2.5-0.5b-instruct-q5_k_m.gguf",
          "quantization": "q5_k_m",
          "contextLength": 32768,
          "hfRepo": "Qwen/Qwen2.5-0.5B-Instruct-GGUF"
        },
        {
          "id": "qwen2.5-1.5b-instruct-q5_k_m",
          "name": "Qwen2.5 1.5B",
          "size": "1.3GB",
          "sizeBytes": 1395864371,
          "description": "Small model, good for basic tasks",
          "fileName": "qwen2.5-1.5b-instruct-q5_k_m.gguf",
          "quantization": "q5_k_m",
          "contextLength": 32768,
          "hfRepo": "Qwen/Qwen2.5-1.5B-Instruct-GGUF"
        },
        {
          "id": "qwen2.5-3b-instruct-q5_k_m",
          "name": "Qwen2.5 3B",
          "size": "2.4GB",
          "sizeBytes": 2620055552,
          "description": "Balanced model for general use",
          "fileName": "qwen2.5-3b-instruct-q5_k_m.gguf",
          "quantization": "q5_k_m",
          "contextLength": 32768,
          "hfRepo": "Qwen/Qwen2.5-3B-Instruct-GGUF"
        },
        {
          "id": "qwen2.5-7b-instruct-q4_k_m",
          "name": "Qwen2.5 7B",
          "size": "4.7GB",
          "sizeBytes": 5025128858,
          "description": "Large model with high quality (Q4_K_M)",
          "fileName": "Qwen2.5-7B-Instruct-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 128000,
          "hfRepo": "bartowski/Qwen2.5-7B-Instruct-GGUF"
        },
        {
          "id": "qwen2.5-7b-instruct-q5_k_m",
          "name": "Qwen2.5 7B (Q5)",
          "size": "5.4GB",
          "sizeBytes": 5841530470,
          "description": "Large model, high quality reasoning (Q5_K_M)",
          "fileName": "Qwen2.5-7B-Instruct-Q5_K_M.gguf",
          "quantization": "q5_k_m",
          "contextLength": 128000,
          "hfRepo": "bartowski/Qwen2.5-7B-Instruct-GGUF"
        }
      ]
    },
    {
      "id": "mistral",
      "name": "Mistral AI",
      "baseUrl": "https://huggingface.co",
      "promptTemplate": "[INST] {system}\n\n{user} [/INST]",
      "models": [
        {
          "id": "mistral-7b-instruct-v0.3-q4_k_m",
          "name": "Mistral 7B Instruct v0.3",
          "size": "4.4GB",
          "sizeBytes": 4692635648,
          "description": "Fast and efficient instruction model",
          "fileName": "Mistral-7B-Instruct-v0.3-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 32768,
          "hfRepo": "bartowski/Mistral-7B-Instruct-v0.3-GGUF",
          "recommended": true
        },
        {
          "id": "mistral-7b-instruct-v0.3-q5_k_m",
          "name": "Mistral 7B Instruct v0.3 (Q5)",
          "size": "5.1GB",
          "sizeBytes": 5519900672,
          "description": "Higher quality instruction model",
          "fileName": "Mistral-7B-Instruct-v0.3-Q5_K_M.gguf",
          "quantization": "q5_k_m",
          "contextLength": 32768,
          "hfRepo": "bartowski/Mistral-7B-Instruct-v0.3-GGUF"
        }
      ]
    },
    {
      "id": "llama",
      "name": "Meta Llama",
      "baseUrl": "https://huggingface.co",
      "promptTemplate": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\n{system}<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n{user}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n",
      "models": [
        {
          "id": "llama-3.2-1b-instruct-q4_k_m",
          "name": "Llama 3.2 1B",
          "size": "0.8GB",
          "sizeBytes": 847249408,
          "description": "Tiny model for edge devices",
          "fileName": "Llama-3.2-1B-Instruct-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 131072,
          "hfRepo": "bartowski/Llama-3.2-1B-Instruct-GGUF"
        },
        {
          "id": "llama-3.2-3b-instruct-q4_k_m",
          "name": "Llama 3.2 3B",
          "size": "2.0GB",
          "sizeBytes": 2168958976,
          "description": "Small but capable multilingual model",
          "fileName": "Llama-3.2-3B-Instruct-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 131072,
          "hfRepo": "bartowski/Llama-3.2-3B-Instruct-GGUF",
          "recommended": true
        },
        {
          "id": "llama-3.1-8b-instruct-q4_k_m",
          "name": "Llama 3.1 8B",
          "size": "4.9GB",
          "sizeBytes": 5282717696,
          "description": "Powerful model with great performance",
          "fileName": "Meta-Llama-3.1-8B-Instruct-Q4_K_M.gguf",
          "quantization": "q4_k_m",
          "contextLength": 131072,
          "hfRepo": "bartowski/Meta-Llama-3.1-8B-Instruct-GGUF"
        }
      ]
    },
    {
      "id": "openai-oss",
      "name": "OpenAI OSS",
      "baseUrl": "https://huggingface.co",
      "promptTemplate": "<|im_start|>system\n{system}<|im_end|>\n<|im_start|>user\n{user}<|im_end|>\n<|im_start|>assistant\n",
      "models": [
        {
          "id": "gpt-oss-20b-mxfp4",
          "name": "GPT-OSS 20B",
          "size": "12.1GB",
          "sizeBytes": 12999763968,
          "description": "OpenAI's open-weight model for consumer hardware",
          "fileName": "gpt-oss-20b-mxfp4.gguf",
          "quantization": "mxfp4",
          "contextLength": 128000,
          "hfRepo": "ggml-org/gpt-oss-20b-GGUF",
          "recommended": true
        }
      ]
    }
  ],
  "openwhisprCloudModels": {
    "tiers": [
      {
        "id": "fast",
        "label": "Fast",
        "provider": "groq",
        "models": [
          {
            "id": "llama-3.3-70b-versatile",
            "name": "Llama 3.3 70B",
            "description": "Fast, high-quality reasoning",
            "recommended": true
          },
          {
            "id": "llama-3.1-8b-instant",
            "name": "Llama 3.1 8B",
            "description": "Ultra-fast, low latency"
          }
        ]
      },
      {
        "id": "balanced",
        "label": "Balanced",
        "provider": "openrouter",
        "models": [
          {
            "id": "anthropic/claude-sonnet-4",
            "name": "Claude Sonnet 4",
            "description": "Balanced performance and quality",
            "recommended": true
          },
          {
            "id": "google/gemini-2.5-flash",
            "name": "Gemini 2.5 Flash",
            "description": "Fast with strong reasoning"
          }
        ]
      },
      {
        "id": "quality",
        "label": "Quality",
        "provider": "openrouter",
        "models": [
          {
            "id": "anthropic/claude-opus-4",
            "name": "Claude Opus 4",
            "description": "Most capable, highest quality",
            "recommended": true
          },
          {
            "id": "openai/gpt-4.1",
            "name": "GPT-4.1",
            "description": "Strong general-purpose reasoning"
          }
        ]
      }
    ]
  }
}
